{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40fbfd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current key (last 10 chars): ...Ci0JLQJj6O\n",
      "Key starts with 'gsk_': True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Check if the key is the same as the one you think you updated\n",
    "api_key = os.getenv('GROQ_API_KEY')\n",
    "print(f\"Current key (last 10 chars): ...{api_key[-10:]}\")\n",
    "print(f\"Key starts with 'gsk_': {api_key.startswith('gsk_') if api_key else 'No key found'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "214fe418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm just a language model, so I don't have emotions or feelings like humans do, but I'm functioning properly and ready to assist you with any questions or tasks you may have. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the model\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "\n",
    "# Get a response\n",
    "response = llm.invoke(\"Hello! How are you today?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52f1f959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c17262",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[\n",
    "    \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\",\n",
    "    \"https://langchain-ai.github.io/langgraph/tutorials/workflows/\",\n",
    "    \"https://langchain-ai.github.io/langgraph/how-tos/map-reduce/\"\n",
    "]\n",
    "\n",
    "docs=[WebBaseLoader(url).load() for url in urls ]\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153a20bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list=[item for sublist in docs for item in sublist]\n",
    "print(doc_list)\n",
    "text_splitter= RecursiveCharacterTextSplitter(chunk_size=900,chunk_overlap=100)\n",
    "doc_splitter=text_splitter.split_documents(doc_list)\n",
    "print(doc_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be532342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "Embeddings_ollama=(OllamaEmbeddings(model=\"mxbai-embed-large:335m\"))\n",
    "Embeddings_ollama\n",
    "\n",
    "vectorstorage=FAISS.from_documents(\n",
    "    documents=doc_splitter,\n",
    "    embedding=Embeddings_ollama\n",
    ")\n",
    "retriver=vectorstorage.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a46706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver.invoke(\"what is langraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a75a772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriver_tool=create_retriever_tool(\n",
    "    retriver,\n",
    "    \"retriver_vector_db_bolg\",\n",
    "    \"Search anf run information about Langgraph\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83f17e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='retriver_vector_db_bolg', description='Search anf run information about Langgraph', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x0000027C0107CD60>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000027C01056270>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x0000027C0107E160>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000027C01056270>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriver_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051c3b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_urls = [\n",
    "    \"https://python.langchain.com/docs/tutorials/\",\n",
    "    \"https://python.langchain.com/docs/tutorials/chatbot/\",\n",
    "    \"https://python.langchain.com/docs/tutorials/qa_chat_history/\",\n",
    "]\n",
    "docs=[WebBaseLoader(url).load() for url in langchain_urls ]\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f40ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "doc_listing=[item for sublist in docs for item in sublist]\n",
    "print(doc_listing)\n",
    "\n",
    "text_split= RecursiveCharacterTextSplitter(\n",
    "    chunk_size=900,chunk_overlap=100\n",
    ")\n",
    "\n",
    "doc_split=text_split.split_documents(doc_listing)\n",
    "print(doc_split)\n",
    "\n",
    "vectorstoragelangchain=FAISS.from_documents(\n",
    "    documents=doc_split,\n",
    "    embedding=Embeddings_ollama\n",
    ")\n",
    "retriverlangchain=vectorstoragelangchain.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53b6a671",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver_tool_cahin=create_retriever_tool(\n",
    "    retriver,\n",
    "    \"retriver_vector_langchin_bolg\",\n",
    "    \"Search and run information about LangChain\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf65d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[retriver_tool,retriver_tool_cahin]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad270280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated,Sequence,Literal\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage,HumanMessage,AIMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pydantic import BaseModel,Field\n",
    "from langchain import hub\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages:Annotated[Sequence[BaseMessage],add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9942a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(state):\n",
    "    \"\"\"\n",
    "    Invokes the agent model to generate a response based on the current state. Given\n",
    "    the question, it will decide to retrieve using the retriever tool, or simply end.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the agent response appended to messages\n",
    "    \"\"\"\n",
    "    print(\"---CALL AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "    model = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "    model = model.bind_tools(tools)\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d1818ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Edges\n",
    "def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        str: A decision for whether the documents are relevant or not\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK RELEVANCE---\")\n",
    "\n",
    "    # Data model\n",
    "    class grade(BaseModel):\n",
    "        \"\"\"Binary score for relevance check.\"\"\"\n",
    "\n",
    "        binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
    "\n",
    "    # LLM\n",
    "    model = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "\n",
    "    # LLM with tool and validation\n",
    "    llm_with_tool = model.with_structured_output(grade)\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    # Chain\n",
    "    chain = prompt | llm_with_tool\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    question = messages[0].content\n",
    "    docs = last_message.content\n",
    "\n",
    "    scored_result = chain.invoke({\"question\": question, \"context\": docs})\n",
    "\n",
    "    score = scored_result.binary_score\n",
    "\n",
    "    if score == \"yes\":\n",
    "        print(\"---DECISION: DOCS RELEVANT---\")\n",
    "        return \"generate\"\n",
    "\n",
    "    else:\n",
    "        print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
    "        print(score)\n",
    "        return \"rewrite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63026c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state) :\n",
    "    \"\"\"\n",
    "    Generate the answer\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict:The updated message\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"--Generate--\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    docs=last_message.content\n",
    "\n",
    "    prompt=hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "    llm=ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "    rag_chain=prompt |llm | StrOutputParser()\n",
    "\n",
    "    response=rag_chain.invoke({\"context\":docs,\"question\":question})\n",
    "    #return {\"messages\":[response]}\n",
    "    return {\"messages\":[AIMessage(content=response)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3a18a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\" \\n \n",
    "    Look at the input and try to reason about the underlying semantic intent / meaning. \\n \n",
    "    Here is the initial question:\n",
    "    \\n ------- \\n\n",
    "    {question} \n",
    "    \\n ------- \\n\n",
    "    Formulate an improved question: \"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Grader\n",
    "    model = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "    response = model.invoke(msg)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6177d0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "workflow.add_node(\"agent\", agent)  # agent\n",
    "retrieve = ToolNode([retriver_tool,retriver_tool_cahin])\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieval\n",
    "workflow.add_node(\"rewrite\", rewrite)  # Re-writing the question\n",
    "workflow.add_node(\n",
    "    \"generate\", generate\n",
    ")  # Generating a response after we know the documents are relevant\n",
    "# Call agent node to decide to retrieve or not\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# Decide whether to retrieve\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    # Assess agent decision\n",
    "    tools_condition,\n",
    "    {\n",
    "        # Translate the condition outputs to nodes in our graph\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Edges taken after the `action` node is called.\n",
    "# workflow.add_conditional_edges(\n",
    "#     \"retrieve\",\n",
    "#     # Assess agent decision\n",
    "#     grade_documents,\n",
    "# )\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    grade_documents,\n",
    "    {\n",
    "        \"generate\": \"generate\",\n",
    "        \"rewrite\": \"rewrite\",\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"generate\", END)\n",
    "workflow.add_edge(\"rewrite\", \"agent\")\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()\n",
    "from IPython.display import Image, display\n",
    "#display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc34cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# The input must be a list of BaseMessage objects\n",
    "graph.invoke({\"messages\": [HumanMessage(content=\"What is Langraph?\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92a8c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"messages\": [HumanMessage(content=\"What is LangChain?\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce7a48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"messages\": [HumanMessage(content=\"What is Machine Learning?\")]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
