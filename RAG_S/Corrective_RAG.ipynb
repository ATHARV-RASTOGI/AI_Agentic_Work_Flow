{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d57d64ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"TAVILY_API_KEY\"]=os.getenv(\"TAVILY_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm=ChatGroq(model=\"qwen/qwen3-32b\")\n",
    "response = llm.invoke(\"Hello! How are you today?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ba8ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embd=(OllamaEmbeddings(model=\"mxbai-embed-large:335m\"))\n",
    "\n",
    "urls=[\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\"\n",
    "\n",
    "]\n",
    "\n",
    "docs= [WebBaseLoader(url).load() for url in urls]\n",
    "\n",
    "# docs_list = []\n",
    "# for url in urls:\n",
    "#     loaded_docs = WebBaseLoader(url).load()\n",
    "#     docs_list.extend(loaded_docs)\n",
    "\n",
    "docs_list=[items for sublist in docs for items in sublist]\n",
    "\n",
    "# docs_list = []\n",
    "# for sublist in docs:\n",
    "#     for item in sublist:\n",
    "#         docs_list.append(item)\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=500,chunk_overlap=0\n",
    ")\n",
    "doc_splits=text_splitter.split_documents(docs_list)\n",
    "\n",
    "#Add Vector Store\n",
    "vectorstore=FAISS.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=embd\n",
    ")\n",
    "\n",
    "\n",
    "retriever=vectorstore.as_retriever()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9709c66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created successfully!\n",
      "Number of original documents: 3\n",
      "Number of document chunks (vectors): 88\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Vector store created successfully!\")\n",
    "print(f\"Number of original documents: {len(docs_list)}\")\n",
    "print(f\"Number of document chunks (vectors): {len(doc_splits)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d700d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "### Retrieval Grader\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "# LLM with function call\n",
    "llm = ChatGroq(model=\"qwen/qwen3-32b\")\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# Prompt\n",
    "system =\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keywords or semantic meaning related to the question, grade it as relevant. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    \n",
    "    Here are some examples:\n",
    "    \n",
    "    Example 1:\n",
    "    Question: What are the main components of an LLM-powered autonomous agent?\n",
    "    Document: The architecture consists of several key components: a central controller (often an LLM), long-term and short-term memory stores, planning modules, and a set of tools that the agent can use.\n",
    "    Answer: yes\n",
    "    \n",
    "    Example 2:\n",
    "    Question: What was the score of the cricket match yesterday?\n",
    "    Document: The sky is blue due to a phenomenon called Rayleigh scattering, where shorter wavelengths of light are scattered more effectively by the molecules in the atmosphere.\n",
    "    Answer: no\n",
    "    \"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "##chain the prompt with the LLM\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "question = \"What is a Agent\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking \"What is an Agent?\" and I need to use the provided context to answer. Let me look through the documents.\n",
      "\n",
      "The first document mentions that an agent is built with LLM as the core controller. It's part of an autonomous system. The components include Planning, Memory, and Tool Use. Planning involves breaking down tasks into subgoals and self-reflection. Memory has short-term and long-term, with long-term using external storage. Tool use allows calling APIs for additional info.\n",
      "\n",
      "Another document repeats similar points, emphasizing LLM as the brain. The agent can handle complex tasks by decomposing them, learn from mistakes, and use external tools. Examples like AutoGPT are given.\n",
      "\n",
      "So, putting it together: An agent here is an autonomous system using LLM as its core. It plans tasks, uses memory (both short and long-term), and interacts with tools. The key functions are decomposition, reflection, memory retention, and API calls. Need to mention it's a problem-solving system beyond just generating text. Make sure the answer is concise, three sentences max. Avoid jargon but include the main components.\n",
      "</think>\n",
      "\n",
      "An agent, in this context, is an autonomous system powered by a large language model (LLM) that acts as its core controller, enabling complex problem-solving beyond text generation. It uses components like **planning** (breaking tasks into subgoals and self-reflection), **memory** (short-term for context and long-term for persistent data), and **tool use** (calling external APIs for real-time or specialized information). Examples include AutoGPT and BabyAGI, which demonstrate agents tackling multifaceted tasks through iterative planning and execution.\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt=hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "llm=ChatGroq(model=\"qwen/qwen3-32b\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain= prompt | llm | StrOutputParser()\n",
    "\n",
    "generation = rag_chain.invoke({\"context\":docs, \"question\":question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2f6852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, the user asked, \"What is a Agent.\" Let me break this down. First, the question is a bit vague. The word \"Agent\" can mean different things depending on the context. So, the main issue here is that the question lacks specificity.\\n\\nI need to consider possible meanings of \"Agent.\" It could refer to a software agent in computing, a human agent in various industries like insurance or real estate, or even a character in a story. Without context, it\\'s hard to know which one the user is asking about. \\n\\nThe user might not realize the term \"Agent\" is ambiguous. Their underlying intent is likely to understand the definition and different types of agents. They might be a student, a professional in a different field, or someone encountering the term for the first time. \\n\\nTo improve the question, I should ask them to clarify the context. Maybe rephrase the question to ask for definitions in different contexts or specify which type of agent they\\'re interested in. That way, the answer can be more accurate and helpful. \\n\\nI should check if there are common contexts where \"Agent\" is frequently used. For example, software agents, travel agents, insurance agents, etc. Including examples in the question can prompt the user to specify. \\n\\nAlso, considering SEO and Google search optimization, using more specific keywords like \"software agent,\" \"human agent,\" or \"types of agents\" might help. But the primary goal is to get the user to provide the necessary context for a precise answer.\\n\\nSo, the improved question should ask for clarification on the type of agent they\\'re referring to, possibly listing examples to guide them. This approach ensures the answer addresses their actual need without making assumptions.\\n</think>\\n\\n**Improved Question:**  \\n\"What is an \\'agent\\' in different contexts (e.g., software, business, law, or AI), and how does its definition vary across industries?\"  \\n\\n**Reasoning:**  \\nThe original question is vague and ambiguous, as \"agent\" can refer to:  \\n1. **Software/Technology**: A program that acts autonomously (e.g., AI agent).  \\n2. **Business/Career**: A representative (e.g., insurance agent, travel agent).  \\n3. **Law/Politics**: An authorized representative or legal agent.  \\n4. **Entertainment**: A person representing another (e.g., talent agent).  \\n5. **Philosophy/Science**: An entity capable of action or decision-making.  \\n\\nBy specifying \"in different contexts\" and providing examples, the improved question clarifies the intent, encourages comprehensive answers, and aligns with how users might search for this term online (e.g., \"what is an AI agent,\" \"what does an agent do in real estate\"). This also helps avoid confusion between unrelated uses of the term.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###question rewritter \n",
    "\n",
    "system=\"\"\"You are a question re-writter that converts the inputed question to a better version that is optimized \\n\n",
    "           for web and google searches . By looking at the input try to reason about the underlying intent / meaning of the question .\"\"\"\n",
    "\n",
    "re_write_prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the intitial question :\\n\\n {question}\\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_rewiter=re_write_prompt |llm | StrOutputParser()\n",
    "question_rewiter.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "web_search_= TavilySearchResults(k=3)\n",
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class Graph_state(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes :\n",
    "        question:question\n",
    "        generation:LLM generation\n",
    "        web_search: wether to add search \n",
    "        documnets:list of documents\n",
    "    \"\"\"\n",
    "    question:str\n",
    "    generation:str\n",
    "    web_search:str\n",
    "    documents:List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca54745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    web_search = \"No\"\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            web_search = \"Yes\"\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}\n",
    "\n",
    "\n",
    "def transform_query(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates question key with a re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Re-write question\n",
    "    better_question = question_rewiter.invoke({\"question\": question})\n",
    "    return {\"documents\": documents, \"question\": better_question}\n",
    "\n",
    "\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based on the re-phrased question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with appended web results\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Web search\n",
    "    docs = web_search_.invoke({\"query\": question})\n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "    documents.append(web_results)\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    "### Edges\n",
    "\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or re-generate a question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    state[\"question\"]\n",
    "    web_search = state[\"web_search\"]\n",
    "    state[\"documents\"]\n",
    "\n",
    "    if web_search == \"Yes\":\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\n",
    "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8dfa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "workflow = StateGraph(Graph_state)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generate\n",
    "workflow.add_node(\"transform_query\", transform_query)  # transform_query\n",
    "workflow.add_node(\"web_search_node\", web_search)  # web search\n",
    "\n",
    "# Build graph\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"web_search_node\")\n",
    "workflow.add_edge(\"web_search_node\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# Compile\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe998ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1cabe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVE---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n"
     ]
    }
   ],
   "source": [
    "app.invoke({\"question\":\"What are the types of agent memory?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0447be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a251e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c24c60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
